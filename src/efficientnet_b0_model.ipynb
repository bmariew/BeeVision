{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "---\n",
        "\n",
        "This notebook details the complete workflow for building and evaluating a multi-label image classification model using the EfficientNet B0 architecture. The goal is to predict multiple labels simultaneously for each image within a dataset. This notebook uses PyTorch for model building and training, scikit-learn for data splitting and some evaluation metrics. The process is divided into several key steps, outlined below."
      ],
      "metadata": {
        "id": "56AQoT0yB8mY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "blROECOtdXvf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SvCZVWjD89N4"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm.auto import tqdm\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from torchvision import models, transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import itertools\n",
        "from sklearn.metrics import classification_report\n",
        "import random\n",
        "import json\n",
        "from plots import *\n",
        "from helper import *\n",
        "from metrics import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "m1vqiZU3dJGm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb5e402c-cce5-4bcd-802c-73a59673d759"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#be fruitful and multiply\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)"
      ],
      "metadata": {
        "id": "focn7aGms7RP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Files\n",
        "\n",
        "---\n",
        "This step loads the image data and corresponding labels. The image paths are read from a CSV file ('annotations.csv'), which contains filenames and their associated labels with associated feature presence.  The images the dataset used for this project is a collection of images of beehive frames with varying features. The images themselves are loaded from the 'images/raw/' directory.\n"
      ],
      "metadata": {
        "id": "i_b02ipldhk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'data'\n",
        "csv_path = os.path.join(data_dir, 'annotations.csv')\n",
        "img_path = os.path.join(data_dir, 'images')\n",
        "df = pd.read_csv(csv_path)"
      ],
      "metadata": {
        "id": "OHyVkNrM9RDs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definition and Training\n",
        "\n",
        "---\n",
        "\n",
        "A custom dataset class ('CustomImageDataset') is defined to efficiently handle the image and label data during training. The pre-trained EfficientNet-B0 model is loaded, and its final classification layer is adjusted to match the number of output labels (15 in this case). The model is then trained using binary cross-entropy loss ('BCEWithLogitsLoss') and an Adam optimizer. The training process is monitored and logged, with metrics recorded at each epoch."
      ],
      "metadata": {
        "id": "9Mlw0MmidxBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, images, labels, data_transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = data_transform\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label = torch.tensor(label, dtype=torch.float32)\n",
        "        sample = {'Image': image, 'Label': label}\n",
        "        return sample"
      ],
      "metadata": {
        "id": "YPANNyo29d4F"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in label file (annotations.csv)\n",
        "df = pd.read_csv(csv_path)\n",
        "df = df[:5]\n",
        "\n",
        "# Convert all labels to floats, NaN if blank\n",
        "for col in df.columns[1:16]:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# Drop any images with NaNs in label columns\n",
        "df.dropna(subset=df.columns[:16], inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Extract ground truth labels for each image in label file (annotations.csv)\n",
        "labels = []\n",
        "for index, row in df.iterrows():\n",
        "    labels.append(list(row.iloc[1:16]))\n",
        "\n",
        "# Create path for and load in each image in directory\n",
        "image_names = df['filename'].tolist()\n",
        "images = []\n",
        "\n",
        "for img_name in tqdm(image_names):\n",
        "    image_path = os.path.join(img_path, img_name)\n",
        "    image = Image.open(image_path)\n",
        "    if image.mode != 'RGB':\n",
        "        image = image.convert('RGB')\n",
        "    images.append(image)\n",
        "\n",
        "# Split data into train (80%), validation (10%), and test (10%) sets\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(images, labels, test_size=1/10, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=1/9, random_state=42)"
      ],
      "metadata": {
        "id": "aK3cmcfM_IdE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_distribution_train = pd.DataFrame(np.array(y_train).sum(axis=0), columns=['count'], index=df.columns[1:16])\n",
        "at_the_bar(feature_distribution_train['count'], 'Feature Distribution - Training Set', 'feature_distribution_train.png', 'eb0', 'train', save_dir)"
      ],
      "metadata": {
        "id": "ut7rZvKJthZ_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_distribution_val = pd.DataFrame(np.array(y_val).sum(axis=0), columns=['count'], index=df.columns[1:16])\n",
        "at_the_bar(feature_distribution_val['count'], 'Feature Distribution - Validation Set', 'feature_distribution_val.png', 'eb0', 'val', save_dir)"
      ],
      "metadata": {
        "id": "YY7VqV-kthQ8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_distribution_test = pd.DataFrame(np.array(y_test).sum(axis=0), columns=['count'], index=df.columns[1:16])\n",
        "at_the_bar(feature_distribution_test['count'], 'Feature Distribution - Test Set', 'feature_distribution_test.png', 'eb0', 'test', save_dir)"
      ],
      "metadata": {
        "id": "-OiQAVEfthCV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define image transformations\n",
        "eb0_train_datatransform = transforms.Compose([\n",
        "    transforms.Resize(size=(224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "eb0_test_datatransform = transforms.Compose([\n",
        "    transforms.Resize(size=(224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "efficientnet_b0_triv_aug_trans = transforms.Compose([\n",
        "    transforms.Resize(size=(256, 256)),\n",
        "    transforms.TrivialAugmentWide(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "# Create datasets\n",
        "\n",
        "val_data = CustomImageDataset(X_val, y_val, data_transform=eb0_test_datatransform)\n",
        "test_data = CustomImageDataset(X_test, y_test, data_transform=eb0_test_datatransform)\n",
        "\n",
        "# Create data loaders\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "val_dataloader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "\n",
        "# --- EfficientNet-B0 Model Definition ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "weights = models.EfficientNet_B0_Weights.DEFAULT\n",
        "model_eb0 = models.efficientnet_b0(weights=weights).to(device)\n",
        "\n",
        "# Freeze pre-trained layers (optional)\n",
        "for param in model_eb0.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify the final classifier layer\n",
        "input_shape = model_eb0.classifier[1].in_features\n",
        "output_shape = 15\n",
        "model_eb0.classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.2, inplace=True),\n",
        "    nn.Linear(input_shape, output_shape)\n",
        ").to(device)\n",
        "\n",
        "\n",
        "# --- Training and Evaluation ---\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model_eb0.parameters(), lr=0.001)\n",
        "\n"
      ],
      "metadata": {
        "id": "r4KwEpkR97N8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hyperparameter Tuning\n",
        "\n",
        "---\n",
        "To optimize performance, a hyperparameter search is conducted. Differnt combinations of batch size, number of epochs, and learning rate are tested, using both the original data transformations and a new transformation using 'transforms.TriviaAugmentWide'. The results of this search are saved to 'hyperparameter_testing_EfficientNet_B0.csv' for analysis. The best performing hyperparameter set is then saved to 'best_params_eb0'.\n"
      ],
      "metadata": {
        "id": "SCuM4i_8d9yk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = [5, 10]\n",
        "lrs = [.001, .0001, .01]\n",
        "batch_size = [16, 32, 64]\n",
        "\n",
        "hyperparameter_combos = list(itertools.product(batch_size, num_epochs, lrs))\n",
        "results = []"
      ],
      "metadata": {
        "id": "qv4o-c5zeCow"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------------------Hyperparameter Testing--------------------------------------------------\n",
        "# Create two datasets, one for each transform\n",
        "train_data_triv_aug = CustomImageDataset(X_train, y_train, data_transform=efficientnet_b0_triv_aug_trans)\n",
        "train_data_eb0_transform = CustomImageDataset(X_train, y_train, data_transform=eb0_train_datatransform)\n",
        "\n",
        "for transform_name, train_data in [(\"triv_aug\", train_data_triv_aug), (\"eb0_transform\", train_data_eb0_transform)]:\n",
        "    for batch_size, epoch, lr in hyperparameter_combos:\n",
        "        # Create DataLoader based on the current transform\n",
        "        train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
        "        save_dir = f\"runs/{transform_name}/lr_{lr}_batch_{batch_size}_epochs_{epoch}\"\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        writer = SummaryWriter(log_dir=save_dir)\n",
        "\n",
        "        params = {'learning_rate': lr, 'batch_size': batch_size, 'epochs': epoch, 'transform': transform_name}\n",
        "        writer.add_hparams(params, {})\n",
        "\n",
        "        print(f\"Starting training with hyperparameters: lr={lr}, batch_size={batch_size}, epochs={epoch}, transform={transform_name}\")\n",
        "\n",
        "        try:\n",
        "            train_results = train(model=model_eb0,\n",
        "                                  train_dataloader=train_dataloader,\n",
        "                                  test_dataloader=val_dataloader,\n",
        "                                  optimizer=torch.optim.Adam(model_eb0.parameters(), lr=lr),\n",
        "                                  loss_fn=criterion,\n",
        "                                  epochs=epoch,\n",
        "                                  device=device,\n",
        "                                  writer=writer,\n",
        "                                  params=params)\n",
        "\n",
        "            final_test_loss = train_results['test_loss'][-1]\n",
        "            final_test_ham_acc = train_results['test_ham_acc'][-1]\n",
        "            final_test_zero_one_acc = train_results['test_zero_one_acc'][-1]\n",
        "            writer.add_hparams(params, {'Final Test Loss': final_test_loss, 'Final Test Hamming Acc': final_test_ham_acc, 'Final Test Zero-One Acc': final_test_zero_one_acc})\n",
        "\n",
        "            results.append({'transform': transform_name, 'batch_size': batch_size, 'epochs': epoch, 'lr': lr, 'final_test_loss': final_test_loss, 'final_test_ham_acc': final_test_ham_acc, 'final_test_zero_one_acc': final_test_zero_one_acc})\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during training: {e}\")\n",
        "            results.append({'transform': transform_name, 'batch_size': batch_size, 'epochs': epoch, 'lr': lr, 'final_test_loss': float('nan'), 'final_test_ham_acc': float('nan'), 'final_test_zero_one_acc': float('nan')})\n",
        "\n",
        "        finally:\n",
        "            writer.close()\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "hwFlD3naLZRK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save result images\n",
        "save_dir = os.getcwd()"
      ],
      "metadata": {
        "id": "OmjVXnj0oXTO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(results)\n",
        "results_df['final_test_zero_one_acc'] = results_df['final_test_zero_one_acc'].apply(lambda x: x.item())\n",
        "file_path = os.path.join(save_dir, \"hyperparameter_testing_d201.csv\")\n",
        "results_df.to_csv(file_path, index=False)"
      ],
      "metadata": {
        "id": "seYkIpqIiUhL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_row = results_df.loc[results_df['final_test_ham_acc'].idxmax()]\n",
        "\n",
        "best_params = {\n",
        "    'transform': best_row['transform'],\n",
        "    'batch_size': best_row['batch_size'].item(),\n",
        "    'epochs': best_row['epochs'].item(),\n",
        "    'lr': best_row['lr'].item(),\n",
        "    'final_test_loss': best_row['final_test_loss'].item(),\n",
        "    'final_test_ham_acc': best_row['final_test_ham_acc'].item(),\n",
        "    'final_test_zero_one_acc': best_row['final_test_zero_one_acc'].item()\n",
        "}\n",
        "\n",
        "filepath = 'best_params_eb0.json'\n",
        "with open(filepath, 'w') as f:\n",
        "    json.dump(best_params, f, indent=4)\n",
        "print(f\"Best parameters saved to {filepath}\")\n",
        "print(best_params)"
      ],
      "metadata": {
        "id": "XcfqcaBWt6Wm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train with best hyperparameters\n",
        "optimizer = torch.optim.Adam(model_eb0.parameters(), lr=best_params['lr'])\n",
        "train_results = train(model=model_eb0,\n",
        "                      train_dataloader=train_dataloader,\n",
        "                      test_dataloader=val_dataloader,\n",
        "                      optimizer=optimizer,\n",
        "                      loss_fn=criterion,\n",
        "                      epochs=best_params['epochs'],\n",
        "                      device=device)"
      ],
      "metadata": {
        "id": "v1J6kGW1uR8U"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_ham_acc, test_zero_one_acc = test_step(model=model_eb0,\n",
        "                                                        dataloader=test_dataloader,\n",
        "                                                        loss_fn=criterion,\n",
        "                                                        device=device)\n",
        "\n",
        "test_loss = test_loss.item() if isinstance(test_loss, torch.Tensor) else test_loss\n",
        "test_ham_acc = test_ham_acc.item() if isinstance(test_ham_acc, torch.Tensor) else test_ham_acc\n",
        "test_zero_one_acc = test_zero_one_acc.item() if isinstance(test_zero_one_acc, torch.Tensor) else test_zero_one_acc\n",
        "\n",
        "test_results = {\n",
        "    'Test Loss': test_loss,\n",
        "    'Test Hamming Accuracy': test_ham_acc,\n",
        "    'Test Zero-One Accuracy': test_zero_one_acc\n",
        "}\n",
        "\n",
        "json_filepath = os.path.join(save_dir, 'test_results_eb0.json')\n",
        "with open(json_filepath, 'w') as jsonfile:\n",
        "    json.dump(test_results, jsonfile, indent=4)\n",
        "\n",
        "print(f\"Test results saved to {json_filepath}\")\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Hamming Accuracy: {test_ham_acc:.4f}, Test Zero-One Accuracy: {test_zero_one_acc:.4f}\")"
      ],
      "metadata": {
        "id": "ccFGfZBOuYen"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluations\n",
        "\n",
        "---\n",
        "After training, the model is evaluated on a held-out test set using several metrics. These include:\n",
        "*   **Accuracy:** Overall correctness of predictions.\n",
        "*   **Precision:** Proportion of correctly predicted positive labels among all predicted positive labels.\n",
        "*   **Recall:** Proportion of correctly predicted positive labels among all actual positive labels.\n",
        "*   **F1-Score:** Harmonic mean of precision and recall\n",
        "*   **Confusion Matrix:** Visual represnetation of model predictions versus ground truth.\n",
        "*   **ROC AUC:** Area under the ROC curve, measuring the model's ability to distinguish between classes.\n"
      ],
      "metadata": {
        "id": "fNUC-2tpKJf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def how_did_i_do(model, test_dataloader, device):\n",
        "    \"\"\"Evaluates the model and computes metrics.\"\"\"\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_prob = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            inputs = batch['Image'].to(device)\n",
        "            labels = batch['Label'].to(device)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            probabilities = torch.sigmoid(outputs)\n",
        "            y_prob.extend(probabilities.cpu().numpy())\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_prob = np.array(y_prob)\n",
        "\n",
        "    y_pred = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "    accuracy = compute_accuracy(y_true, y_pred)\n",
        "    precision = compute_precision(y_true, y_pred, average='micro')\n",
        "    recall = compute_recall(y_true, y_pred, average='micro')\n",
        "    f1 = compute_f1_score(y_true, y_pred, average='micro')\n",
        "    confusion_mat = compute_confusion_matrix(y_true.flatten(), y_pred.flatten())\n",
        "    roc_auc = compute_roc_auc(y_true.flatten(), y_prob.flatten())\n",
        "    fpr, tpr, roc_auc_value = compute_roc_curve_data(y_true.flatten(), y_prob.flatten())\n",
        "\n",
        "\n",
        "\n",
        "    # Print the metrics\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-Score: {f1}\")\n",
        "    print(f\"Confusion Matrix:\\n{confusion_mat}\")\n",
        "    print(f\"ROC AUC: {roc_auc}\")\n",
        "    print(f\"FPR: {fpr}\")\n",
        "    print(f\"TPR: {tpr}\")\n",
        "    print(f\"ROC AUC Value: {roc_auc_value}\")\n",
        "\n",
        "    return accuracy, precision, recall, f1, confusion_mat, roc_auc, fpr, tpr, roc_auc_value, y_true, y_pred"
      ],
      "metadata": {
        "id": "b9boHGQbKMtq"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy, precision, recall, f1, confusion_mat, roc_auc, fpr, tpr, roc_auc_value, y_true, y_pred = how_did_i_do(model_eb0, test_dataloader, device)"
      ],
      "metadata": {
        "id": "Skh-cAqSKaaP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizations\n",
        "\n",
        "---\n",
        "\n",
        "Finally, visualizations are generated to aid in the understanding of the model's performance. A confusion matrix is plotted to show the distribution of correct and incorre t predictions. Plots comparing training and validation loss and accuracy over epochs are generated as well as visualizations for the AUC."
      ],
      "metadata": {
        "id": "G67JfyCMQT82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix"
      ],
      "metadata": {
        "id": "jose-i7lQYYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(y_true, y_pred, df, 'eb0', save_dir)"
      ],
      "metadata": {
        "id": "1IVh_ncQupCR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_single_confusion_matrix(model_eb0, test_dataloader, device, 'eb0', save_dir)"
      ],
      "metadata": {
        "id": "-PdfhPrgimAE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training and Validation Comparisons per Metric"
      ],
      "metadata": {
        "id": "i0w69s5sQppm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training_validation_metrics(save_dir, train_results, 'eb0')"
      ],
      "metadata": {
        "id": "kfNXt546i-Dj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Area Under the Curve (AUC)"
      ],
      "metadata": {
        "id": "tiL3KLN0QwIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_roc_curves(save_dir, model_eb0, test_dataloader, device, 'eb0')"
      ],
      "metadata": {
        "id": "8VFt3ya5jDRG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "---\n",
        "\n",
        "1.   **Gallery of transformations:**<br>\n",
        "      PyTorch.org. \"Plot Transforms Illustrations.\" PyTorch, https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_illustrations.html#sphx-glr-auto-examples-transforms-plot-transforms-illustrations-py. Accessed 01 November 2024.\n",
        "2.   **DataLoaders:**<br>\n",
        "      PyTorch.org. \"torch.utils.data.DataLoader — PyTorch 2.1.0+cu118 documentation.\" PyTorch, https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader. Accessed 03 November 2024.\n",
        "3.    **PyTorch Deep Learning (Train and Test Loops):**<br>\n",
        "      Bourke, Daniel. \"engine.py.\" pytorch-deep-learning, https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/going_modular/engine.py. Accessed 03 November 2024.\n",
        "4.    **PyTorch Torchvision Blog Post:**<br>\n",
        "      PyTorch Blog. \"How to Train State-of-the-Art Models Using Torchvision’s Latest Primitives.\" PyTorch, https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/. Accessed 03 November 2024.\n",
        "5.    **EfficientNet-B0 Tutorial:**<br>\n",
        "      DebuggerCafe. \"Transfer Learning Using EfficientNet PyTorch.\" DebuggerCafe, https://debuggercafe.com/transfer-learning-using-efficientnet-pytorch/. Accessed 14 November 2024."
      ],
      "metadata": {
        "id": "Gjr3e4URGRRR"
      }
    }
  ]
}